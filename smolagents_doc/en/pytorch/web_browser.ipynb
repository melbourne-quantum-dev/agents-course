{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBNrNQtObW78",
        "outputId": "ae142ed9-47de-4538-e79e-324a28f37f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting smolagents\n",
            "  Downloading smolagents-1.9.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from smolagents) (0.28.1)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from smolagents) (2.32.3)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from smolagents) (13.9.4)\n",
            "Collecting pandas>=2.2.3 (from smolagents)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from smolagents) (3.1.5)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from smolagents) (11.1.0)\n",
            "Collecting markdownify>=0.14.1 (from smolagents)\n",
            "  Downloading markdownify-1.0.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting duckduckgo-search>=6.3.7 (from smolagents)\n",
            "  Downloading duckduckgo_search-7.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting python-dotenv (from smolagents)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search>=6.3.7->smolagents) (8.1.8)\n",
            "Collecting primp>=0.14.0 (from duckduckgo-search>=6.3.7->smolagents)\n",
            "  Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search>=6.3.7->smolagents) (5.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.0->smolagents) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.0->smolagents) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.0->smolagents) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.0->smolagents) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.0->smolagents) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.0->smolagents) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.4->smolagents) (3.0.2)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.11/dist-packages (from markdownify>=0.14.1->smolagents) (4.13.3)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.11/dist-packages (from markdownify>=0.14.1->smolagents) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->smolagents) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->smolagents) (2.18.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9->markdownify>=0.14.1->smolagents) (2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents) (0.1.2)\n",
            "Downloading smolagents-1.9.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-7.5.0-py3-none-any.whl (20 kB)\n",
            "Downloading markdownify-1.0.0-py3-none-any.whl (13 kB)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, primp, pandas, markdownify, duckduckgo-search, smolagents\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed duckduckgo-search-7.5.0 markdownify-1.0.0 pandas-2.2.3 primp-0.14.0 python-dotenv-1.0.1 smolagents-1.9.2\n"
          ]
        }
      ],
      "source": [
        "# Installation\n",
        "! pip install smolagents\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/smolagents.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYZ6ZN34bW79"
      },
      "source": [
        "# Web Browser Automation with Agents 🤖🌐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arAHIA9obW7-"
      },
      "source": [
        "In this notebook, we'll create an **agent-powered web browser automation system**! This system can navigate websites, interact with elements, and extract information automatically.\n",
        "\n",
        "The agent will be able to:\n",
        "\n",
        "- [x] Navigate to web pages\n",
        "- [x] Click on elements\n",
        "- [x] Search within pages\n",
        "- [x] Handle popups and modals\n",
        "- [x] Extract information\n",
        "\n",
        "Let's set up this system step by step!\n",
        "\n",
        "First, run these lines to install the required dependencies:\n",
        "\n",
        "```bash\n",
        "!pip install smolagents selenium helium pillow -q\n",
        "```\n",
        "\n",
        "Let's import our required libraries and set up environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMYi17qebW7_"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from time import sleep\n",
        "\n",
        "import helium\n",
        "from dotenv import load_dotenv\n",
        "from PIL import Image\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "from smolagents import CodeAgent, tool\n",
        "from smolagents.agents import ActionStep\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRFgqSSAbW8A"
      },
      "source": [
        "Now let's create our core browser interaction tools that will allow our agent to navigate and interact with web pages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CskeUPX1bW8A"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_item_ctrl_f(text: str, nth_result: int = 1) -> str:\n",
        "    \"\"\"\n",
        "    Searches for text on the current page via Ctrl + F and jumps to the nth occurrence.\n",
        "    Args:\n",
        "        text: The text to search for\n",
        "        nth_result: Which occurrence to jump to (default: 1)\n",
        "    \"\"\"\n",
        "    elements = driver.find_elements(By.XPATH, f\"//*[contains(text(), '{text}')]\")\n",
        "    if nth_result > len(elements):\n",
        "        raise Exception(f\"Match n°{nth_result} not found (only {len(elements)} matches found)\")\n",
        "    result = f\"Found {len(elements)} matches for '{text}'.\"\n",
        "    elem = elements[nth_result - 1]\n",
        "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", elem)\n",
        "    result += f\"Focused on element {nth_result} of {len(elements)}\"\n",
        "    return result\n",
        "\n",
        "@tool\n",
        "def go_back() -> None:\n",
        "    \"\"\"Goes back to previous page.\"\"\"\n",
        "    driver.back()\n",
        "\n",
        "@tool\n",
        "def close_popups() -> str:\n",
        "    \"\"\"\n",
        "    Closes any visible modal or pop-up on the page. Use this to dismiss pop-up windows!\n",
        "    This does not work on cookie consent banners.\n",
        "    \"\"\"\n",
        "    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB7ibLWdbW8B"
      },
      "source": [
        "Let's set up our browser with Chrome and configure screenshot capabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw_-jWAGbW8B"
      },
      "outputs": [],
      "source": [
        "# Configure Chrome options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument(\"--force-device-scale-factor=1\")\n",
        "chrome_options.add_argument(\"--window-size=1000,1350\")\n",
        "chrome_options.add_argument(\"--disable-pdf-viewer\")\n",
        "chrome_options.add_argument(\"--window-position=0,0\")\n",
        "\n",
        "# Initialize the browser\n",
        "driver = helium.start_chrome(headless=False, options=chrome_options)\n",
        "\n",
        "# Set up screenshot callback\n",
        "def save_screenshot(memory_step: ActionStep, agent: CodeAgent) -> None:\n",
        "    sleep(1.0)  # Let JavaScript animations happen before taking the screenshot\n",
        "    driver = helium.get_driver()\n",
        "    current_step = memory_step.step_number\n",
        "    if driver is not None:\n",
        "        for previous_memory_step in agent.memory.steps:  # Remove previous screenshots for lean processing\n",
        "            if isinstance(previous_memory_step, ActionStep) and previous_memory_step.step_number <= current_step - 2:\n",
        "                previous_memory_step.observations_images = None\n",
        "        png_bytes = driver.get_screenshot_as_png()\n",
        "        image = Image.open(BytesIO(png_bytes))\n",
        "        print(f\"Captured a browser screenshot: {image.size} pixels\")\n",
        "        memory_step.observations_images = [image.copy()]  # Create a copy to ensure it persists\n",
        "\n",
        "    # Update observations with current URL\n",
        "    url_info = f\"Current url: {driver.current_url}\"\n",
        "    memory_step.observations = (\n",
        "        url_info if memory_step.observations is None else memory_step.observations + \"\\n\" + url_info\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J017ovacbW8C"
      },
      "source": [
        "Now let's create our web automation agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rPbpwVubW8D"
      },
      "outputs": [],
      "source": [
        "from smolagents import HfApiModel\n",
        "\n",
        "# Initialize the model\n",
        "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"  # You can change this to your preferred model\n",
        "model = HfApiModel(model_id)\n",
        "\n",
        "# Create the agent\n",
        "agent = CodeAgent(\n",
        "    tools=[go_back, close_popups, search_item_ctrl_f],\n",
        "    model=model,\n",
        "    additional_authorized_imports=[\"helium\"],\n",
        "    step_callbacks=[save_screenshot],\n",
        "    max_steps=20,\n",
        "    verbosity_level=2,\n",
        ")\n",
        "\n",
        "# Import helium for the agent\n",
        "agent.python_executor(\"from helium import *\", agent.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZPtWb3bW8E"
      },
      "source": [
        "The agent needs instructions on how to use Helium for web automation. Here are the instructions we'll provide:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ieruxdSbW8E"
      },
      "outputs": [],
      "source": [
        "helium_instructions = \"\"\"\n",
        "You can use helium to access websites. Don't bother about the helium driver, it's already managed.\n",
        "We've already ran \"from helium import *\"\n",
        "Then you can go to pages!\n",
        "Code:\n",
        "go_to('github.com/trending')\n",
        "```<end_code>\n",
        "\n",
        "You can directly click clickable elements by inputting the text that appears on them.\n",
        "Code:\n",
        "click(\"Top products\")\n",
        "```<end_code>\n",
        "\n",
        "If it's a link:\n",
        "Code:\n",
        "click(Link(\"Top products\"))\n",
        "```<end_code>\n",
        "\n",
        "If you try to interact with an element and it's not found, you'll get a LookupError.\n",
        "In general stop your action after each button click to see what happens on your screenshot.\n",
        "Never try to login in a page.\n",
        "\n",
        "To scroll up or down, use scroll_down or scroll_up with as an argument the number of pixels to scroll from.\n",
        "Code:\n",
        "scroll_down(num_pixels=1200) # This will scroll one viewport down\n",
        "```<end_code>\n",
        "\n",
        "When you have pop-ups with a cross icon to close, don't try to click the close icon by finding its element or targeting an 'X' element (this most often fails).\n",
        "Just use your built-in tool `close_popups` to close them:\n",
        "Code:\n",
        "close_popups()\n",
        "```<end_code>\n",
        "\n",
        "You can use .exists() to check for the existence of an element. For example:\n",
        "Code:\n",
        "if Text('Accept cookies?').exists():\n",
        "    click('I accept')\n",
        "```<end_code>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSoBTk2kbW8F"
      },
      "source": [
        "Now we can run our agent with a task! Let's try finding information on Wikipedia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4rcJOWfbW8F"
      },
      "outputs": [],
      "source": [
        "search_request = \"\"\"\n",
        "Please navigate to https://en.wikipedia.org/wiki/Chicago and give me a sentence containing the word \"1992\" that mentions a construction accident.\n",
        "\"\"\"\n",
        "\n",
        "agent_output = agent.run(search_request + helium_instructions)\n",
        "print(\"Final output:\")\n",
        "print(agent_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7HykXlSbW8F"
      },
      "source": [
        "You can run different tasks by modifying the request. For example, here's for me to know if I should work harder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx_cZdTdbW8F"
      },
      "outputs": [],
      "source": [
        "github_request = \"\"\"\n",
        "I'm trying to find how hard I have to work to get a repo in github.com/trending.\n",
        "Can you navigate to the profile for the top author of the top trending repo, and give me their total number of commits over the last year?\n",
        "\"\"\"\n",
        "\n",
        "agent_output = agent.run(github_request + helium_instructions)\n",
        "print(\"Final output:\")\n",
        "print(agent_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnUuMwcIbW8F"
      },
      "source": [
        "The system is particularly effective for tasks like:\n",
        "- Data extraction from websites\n",
        "- Web research automation\n",
        "- UI testing and verification\n",
        "- Content monitoring"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}